name: "scraping"
on:
  schedule:
    - cron: "0 10 * * 0" #毎週日曜日 19時に実行(JST)

env:
  PR_TITLE: $(date +"%Y/%m/%d")_Syllabus_Data_Update
  DEST_BRANCH: master

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 600

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set current datetime as env variable
        env:
          TZ: "Asia/Tokyo"
        run: echo "CURRENT_DATETIME=$(date +"%Y/%m/%d")" >> $GITHUB_ENV

      - name: Create new branch
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git switch -c update_${{ env.CURRENT_DATETIME }}
          git push -u origin update_${{ env.CURRENT_DATETIME }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ./requirements.txt

      - name: Perform scraping
        run: |
          python ./main.py

      - name: Add and Commit
        uses: EndBug/add-and-commit@v9
        with:
          branch: ${{ env.CURRENT_DATETIME }}_syllabus_data_update
          message: Syllabus Data Update
          add: .

      - name: Create pull request
        uses: repo-sync/pull-request@v2
        with:
          source_branch: update_${{ env.CURRENT_DATETIME }}
          destination_branch: ${{ env.DEST_BRANCH }}
          pr_title: ${{ env.PR_TITLE }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
